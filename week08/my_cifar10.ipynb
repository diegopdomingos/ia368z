{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar10 - exercicio de classificar 3 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer classificação de 3 classes usando rede neural convolucional.\n",
    "Não utilizar o pacote sklearn. Apenas o Keras e o NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não utilizar a função de acompanhamento de gráficos durante o treinamento.\n",
    "\n",
    "Gerar uma figura mosaic que contenha as 5 imagens de classificação correta de menor probabilidade de predição.\n",
    "\n",
    "Gerar esta figura com o nome: cifar_fig.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from sklearn.datasets import load_iris\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from itertools import count\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/etc/jupyterhub/ia368z_2s2017/datasets/cifar10-redux.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 3, 32, 32), (2000,), (500, 3, 32, 32), (500,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), dtype('uint8'), dtype('uint8'), dtype('int64'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype, y_train.dtype, X_test.dtype, y_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "X_train = torch.from_numpy(X_train.astype('float32')).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train-3).type(torch.LongTensor)\n",
    "X_test = torch.from_numpy(X_test.astype('float32')).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test-3).type(torch.LongTensor)\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "\n",
    "\n",
    "# Split the X_train to validation\n",
    "X_val = X_train[1500:]\n",
    "y_val = y_train[1500:]\n",
    "X_train = X_train[0:1499]\n",
    "y_train = y_train[0:1499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SmallCNN(nclasses,input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape,data_format=\"channels_first\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(150))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nclasses))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Main cell\n",
    "model = Net()\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X,y,epoch,b=10):\n",
    "    model.train()\n",
    "    #random = np.random.randint(0,len(X),size=(1,b))\n",
    "    data, target = Variable(X.float()), Variable(y)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, len(data), len(X),100. *len(data) / len(X), loss.data[0]))\n",
    "\n",
    "def test(X,y):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    data, target = Variable(X.float(), volatile=True), Variable(y)\n",
    "    output = model(data)\n",
    "    test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(X)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(X),\n",
    "        100. * correct / len(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1499/1499 (100%)]\tLoss: 1.103089\n",
      "\n",
      "Test set: Average loss: 1.1014, Accuracy: 158/500 (32%)\n",
      "\n",
      "Train Epoch: 2 [1499/1499 (100%)]\tLoss: 1.101051\n",
      "\n",
      "Test set: Average loss: 1.0998, Accuracy: 158/500 (32%)\n",
      "\n",
      "Train Epoch: 3 [1499/1499 (100%)]\tLoss: 1.099288\n",
      "\n",
      "Test set: Average loss: 1.0987, Accuracy: 158/500 (32%)\n",
      "\n",
      "Train Epoch: 4 [1499/1499 (100%)]\tLoss: 1.097698\n",
      "\n",
      "Test set: Average loss: 1.0978, Accuracy: 205/500 (41%)\n",
      "\n",
      "Train Epoch: 5 [1499/1499 (100%)]\tLoss: 1.096400\n",
      "\n",
      "Test set: Average loss: 1.0965, Accuracy: 209/500 (42%)\n",
      "\n",
      "Train Epoch: 6 [1499/1499 (100%)]\tLoss: 1.094867\n",
      "\n",
      "Test set: Average loss: 1.0948, Accuracy: 204/500 (41%)\n",
      "\n",
      "Train Epoch: 7 [1499/1499 (100%)]\tLoss: 1.092651\n",
      "\n",
      "Test set: Average loss: 1.0932, Accuracy: 183/500 (37%)\n",
      "\n",
      "Train Epoch: 8 [1499/1499 (100%)]\tLoss: 1.090142\n",
      "\n",
      "Test set: Average loss: 1.0905, Accuracy: 194/500 (39%)\n",
      "\n",
      "Train Epoch: 9 [1499/1499 (100%)]\tLoss: 1.086797\n",
      "\n",
      "Test set: Average loss: 1.0865, Accuracy: 210/500 (42%)\n",
      "\n",
      "Train Epoch: 10 [1499/1499 (100%)]\tLoss: 1.082395\n",
      "\n",
      "Test set: Average loss: 1.0826, Accuracy: 214/500 (43%)\n",
      "\n",
      "Train Epoch: 11 [1499/1499 (100%)]\tLoss: 1.077636\n",
      "\n",
      "Test set: Average loss: 1.0787, Accuracy: 213/500 (43%)\n",
      "\n",
      "Train Epoch: 12 [1499/1499 (100%)]\tLoss: 1.071983\n",
      "\n",
      "Test set: Average loss: 1.0739, Accuracy: 211/500 (42%)\n",
      "\n",
      "Train Epoch: 13 [1499/1499 (100%)]\tLoss: 1.065501\n",
      "\n",
      "Test set: Average loss: 1.0672, Accuracy: 211/500 (42%)\n",
      "\n",
      "Train Epoch: 14 [1499/1499 (100%)]\tLoss: 1.058110\n",
      "\n",
      "Test set: Average loss: 1.0614, Accuracy: 211/500 (42%)\n",
      "\n",
      "Train Epoch: 15 [1499/1499 (100%)]\tLoss: 1.049729\n",
      "\n",
      "Test set: Average loss: 1.0536, Accuracy: 221/500 (44%)\n",
      "\n",
      "Train Epoch: 16 [1499/1499 (100%)]\tLoss: 1.040541\n",
      "\n",
      "Test set: Average loss: 1.0462, Accuracy: 220/500 (44%)\n",
      "\n",
      "Train Epoch: 17 [1499/1499 (100%)]\tLoss: 1.031276\n",
      "\n",
      "Test set: Average loss: 1.0436, Accuracy: 216/500 (43%)\n",
      "\n",
      "Train Epoch: 18 [1499/1499 (100%)]\tLoss: 1.024438\n",
      "\n",
      "Test set: Average loss: 1.0517, Accuracy: 214/500 (43%)\n",
      "\n",
      "Train Epoch: 19 [1499/1499 (100%)]\tLoss: 1.037159\n",
      "\n",
      "Test set: Average loss: 1.0418, Accuracy: 209/500 (42%)\n",
      "\n",
      "Train Epoch: 20 [1499/1499 (100%)]\tLoss: 1.018714\n",
      "\n",
      "Test set: Average loss: 1.0477, Accuracy: 216/500 (43%)\n",
      "\n",
      "Train Epoch: 21 [1499/1499 (100%)]\tLoss: 1.023082\n",
      "\n",
      "Test set: Average loss: 1.0284, Accuracy: 242/500 (48%)\n",
      "\n",
      "Train Epoch: 22 [1499/1499 (100%)]\tLoss: 1.007074\n",
      "\n",
      "Test set: Average loss: 1.0362, Accuracy: 238/500 (48%)\n",
      "\n",
      "Train Epoch: 23 [1499/1499 (100%)]\tLoss: 1.015845\n",
      "\n",
      "Test set: Average loss: 1.0242, Accuracy: 225/500 (45%)\n",
      "\n",
      "Train Epoch: 24 [1499/1499 (100%)]\tLoss: 0.998414\n",
      "\n",
      "Test set: Average loss: 1.0367, Accuracy: 213/500 (43%)\n",
      "\n",
      "Train Epoch: 25 [1499/1499 (100%)]\tLoss: 1.008416\n",
      "\n",
      "Test set: Average loss: 1.0178, Accuracy: 233/500 (47%)\n",
      "\n",
      "Train Epoch: 26 [1499/1499 (100%)]\tLoss: 0.991039\n",
      "\n",
      "Test set: Average loss: 1.0238, Accuracy: 240/500 (48%)\n",
      "\n",
      "Train Epoch: 27 [1499/1499 (100%)]\tLoss: 0.999874\n",
      "\n",
      "Test set: Average loss: 1.0111, Accuracy: 249/500 (50%)\n",
      "\n",
      "Train Epoch: 28 [1499/1499 (100%)]\tLoss: 0.984940\n",
      "\n",
      "Test set: Average loss: 1.0196, Accuracy: 235/500 (47%)\n",
      "\n",
      "Train Epoch: 29 [1499/1499 (100%)]\tLoss: 0.991054\n",
      "\n",
      "Test set: Average loss: 1.0083, Accuracy: 237/500 (47%)\n",
      "\n",
      "Train Epoch: 30 [1499/1499 (100%)]\tLoss: 0.979005\n",
      "\n",
      "Test set: Average loss: 1.0120, Accuracy: 246/500 (49%)\n",
      "\n",
      "Train Epoch: 31 [1499/1499 (100%)]\tLoss: 0.983125\n",
      "\n",
      "Test set: Average loss: 1.0019, Accuracy: 250/500 (50%)\n",
      "\n",
      "Train Epoch: 32 [1499/1499 (100%)]\tLoss: 0.971450\n",
      "\n",
      "Test set: Average loss: 1.0067, Accuracy: 240/500 (48%)\n",
      "\n",
      "Train Epoch: 33 [1499/1499 (100%)]\tLoss: 0.975513\n",
      "\n",
      "Test set: Average loss: 0.9953, Accuracy: 252/500 (50%)\n",
      "\n",
      "Train Epoch: 34 [1499/1499 (100%)]\tLoss: 0.964136\n",
      "\n",
      "Test set: Average loss: 1.0000, Accuracy: 248/500 (50%)\n",
      "\n",
      "Train Epoch: 35 [1499/1499 (100%)]\tLoss: 0.968949\n",
      "\n",
      "Test set: Average loss: 0.9895, Accuracy: 257/500 (51%)\n",
      "\n",
      "Train Epoch: 36 [1499/1499 (100%)]\tLoss: 0.956398\n",
      "\n",
      "Test set: Average loss: 0.9948, Accuracy: 244/500 (49%)\n",
      "\n",
      "Train Epoch: 37 [1499/1499 (100%)]\tLoss: 0.960139\n",
      "\n",
      "Test set: Average loss: 0.9866, Accuracy: 258/500 (52%)\n",
      "\n",
      "Train Epoch: 38 [1499/1499 (100%)]\tLoss: 0.950731\n",
      "\n",
      "Test set: Average loss: 0.9854, Accuracy: 255/500 (51%)\n",
      "\n",
      "Train Epoch: 39 [1499/1499 (100%)]\tLoss: 0.948664\n",
      "\n",
      "Test set: Average loss: 0.9861, Accuracy: 250/500 (50%)\n",
      "\n",
      "Train Epoch: 40 [1499/1499 (100%)]\tLoss: 0.948461\n",
      "\n",
      "Test set: Average loss: 0.9771, Accuracy: 260/500 (52%)\n",
      "\n",
      "Train Epoch: 41 [1499/1499 (100%)]\tLoss: 0.938328\n",
      "\n",
      "Test set: Average loss: 0.9810, Accuracy: 255/500 (51%)\n",
      "\n",
      "Train Epoch: 42 [1499/1499 (100%)]\tLoss: 0.940592\n",
      "\n",
      "Test set: Average loss: 0.9808, Accuracy: 252/500 (50%)\n",
      "\n",
      "Train Epoch: 43 [1499/1499 (100%)]\tLoss: 0.938628\n",
      "\n",
      "Test set: Average loss: 0.9714, Accuracy: 263/500 (53%)\n",
      "\n",
      "Train Epoch: 44 [1499/1499 (100%)]\tLoss: 0.928024\n",
      "\n",
      "Test set: Average loss: 0.9734, Accuracy: 258/500 (52%)\n",
      "\n",
      "Train Epoch: 45 [1499/1499 (100%)]\tLoss: 0.929434\n",
      "\n",
      "Test set: Average loss: 0.9754, Accuracy: 265/500 (53%)\n",
      "\n",
      "Train Epoch: 46 [1499/1499 (100%)]\tLoss: 0.930942\n",
      "\n",
      "Test set: Average loss: 0.9660, Accuracy: 263/500 (53%)\n",
      "\n",
      "Train Epoch: 47 [1499/1499 (100%)]\tLoss: 0.919687\n",
      "\n",
      "Test set: Average loss: 0.9641, Accuracy: 263/500 (53%)\n",
      "\n",
      "Train Epoch: 48 [1499/1499 (100%)]\tLoss: 0.916532\n",
      "\n",
      "Test set: Average loss: 0.9683, Accuracy: 263/500 (53%)\n",
      "\n",
      "Train Epoch: 49 [1499/1499 (100%)]\tLoss: 0.920558\n",
      "\n",
      "Test set: Average loss: 0.9641, Accuracy: 253/500 (51%)\n",
      "\n",
      "Train Epoch: 50 [1499/1499 (100%)]\tLoss: 0.915483\n",
      "\n",
      "Test set: Average loss: 0.9566, Accuracy: 265/500 (53%)\n",
      "\n",
      "Train Epoch: 51 [1499/1499 (100%)]\tLoss: 0.906914\n",
      "\n",
      "Test set: Average loss: 0.9556, Accuracy: 265/500 (53%)\n",
      "\n",
      "Train Epoch: 52 [1499/1499 (100%)]\tLoss: 0.904199\n",
      "\n",
      "Test set: Average loss: 0.9584, Accuracy: 257/500 (51%)\n",
      "\n",
      "Train Epoch: 53 [1499/1499 (100%)]\tLoss: 0.905959\n",
      "\n",
      "Test set: Average loss: 0.9585, Accuracy: 271/500 (54%)\n",
      "\n",
      "Train Epoch: 54 [1499/1499 (100%)]\tLoss: 0.905715\n",
      "\n",
      "Test set: Average loss: 0.9516, Accuracy: 262/500 (52%)\n",
      "\n",
      "Train Epoch: 55 [1499/1499 (100%)]\tLoss: 0.897376\n",
      "\n",
      "Test set: Average loss: 0.9474, Accuracy: 263/500 (53%)\n",
      "\n",
      "Train Epoch: 56 [1499/1499 (100%)]\tLoss: 0.891618\n",
      "\n",
      "Test set: Average loss: 0.9479, Accuracy: 260/500 (52%)\n",
      "\n",
      "Train Epoch: 57 [1499/1499 (100%)]\tLoss: 0.890863\n",
      "\n",
      "Test set: Average loss: 0.9500, Accuracy: 261/500 (52%)\n",
      "\n",
      "Train Epoch: 58 [1499/1499 (100%)]\tLoss: 0.892015\n",
      "\n",
      "Test set: Average loss: 0.9522, Accuracy: 267/500 (53%)\n",
      "\n",
      "Train Epoch: 59 [1499/1499 (100%)]\tLoss: 0.892403\n",
      "\n",
      "Test set: Average loss: 0.9474, Accuracy: 263/500 (53%)\n",
      "\n",
      "Train Epoch: 60 [1499/1499 (100%)]\tLoss: 0.886192\n",
      "\n",
      "Test set: Average loss: 0.9421, Accuracy: 263/500 (53%)\n",
      "\n",
      "Train Epoch: 61 [1499/1499 (100%)]\tLoss: 0.879278\n",
      "\n",
      "Test set: Average loss: 0.9384, Accuracy: 264/500 (53%)\n",
      "\n",
      "Train Epoch: 62 [1499/1499 (100%)]\tLoss: 0.874731\n",
      "\n",
      "Test set: Average loss: 0.9390, Accuracy: 261/500 (52%)\n",
      "\n",
      "Train Epoch: 63 [1499/1499 (100%)]\tLoss: 0.873896\n",
      "\n",
      "Test set: Average loss: 0.9420, Accuracy: 267/500 (53%)\n",
      "\n",
      "Train Epoch: 64 [1499/1499 (100%)]\tLoss: 0.875018\n",
      "\n",
      "Test set: Average loss: 0.9405, Accuracy: 267/500 (53%)\n",
      "\n",
      "Train Epoch: 65 [1499/1499 (100%)]\tLoss: 0.873891\n",
      "\n",
      "Test set: Average loss: 0.9406, Accuracy: 267/500 (53%)\n",
      "\n",
      "Train Epoch: 66 [1499/1499 (100%)]\tLoss: 0.871013\n",
      "\n",
      "Test set: Average loss: 0.9343, Accuracy: 266/500 (53%)\n",
      "\n",
      "Train Epoch: 67 [1499/1499 (100%)]\tLoss: 0.864131\n",
      "\n",
      "Test set: Average loss: 0.9301, Accuracy: 269/500 (54%)\n",
      "\n",
      "Train Epoch: 68 [1499/1499 (100%)]\tLoss: 0.858474\n",
      "\n",
      "Test set: Average loss: 0.9290, Accuracy: 268/500 (54%)\n",
      "\n",
      "Train Epoch: 69 [1499/1499 (100%)]\tLoss: 0.856034\n",
      "\n",
      "Test set: Average loss: 0.9292, Accuracy: 269/500 (54%)\n",
      "\n",
      "Train Epoch: 70 [1499/1499 (100%)]\tLoss: 0.855580\n",
      "\n",
      "Test set: Average loss: 0.9310, Accuracy: 270/500 (54%)\n",
      "\n",
      "Train Epoch: 71 [1499/1499 (100%)]\tLoss: 0.855246\n",
      "\n",
      "Test set: Average loss: 0.9270, Accuracy: 275/500 (55%)\n",
      "\n",
      "Train Epoch: 72 [1499/1499 (100%)]\tLoss: 0.851910\n",
      "\n",
      "Test set: Average loss: 0.9269, Accuracy: 270/500 (54%)\n",
      "\n",
      "Train Epoch: 73 [1499/1499 (100%)]\tLoss: 0.847538\n",
      "\n",
      "Test set: Average loss: 0.9204, Accuracy: 282/500 (56%)\n",
      "\n",
      "Train Epoch: 74 [1499/1499 (100%)]\tLoss: 0.842593\n",
      "\n",
      "Test set: Average loss: 0.9200, Accuracy: 274/500 (55%)\n",
      "\n",
      "Train Epoch: 75 [1499/1499 (100%)]\tLoss: 0.838843\n",
      "\n",
      "Test set: Average loss: 0.9191, Accuracy: 276/500 (55%)\n",
      "\n",
      "Train Epoch: 76 [1499/1499 (100%)]\tLoss: 0.836757\n",
      "\n",
      "Test set: Average loss: 0.9168, Accuracy: 283/500 (57%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 77 [1499/1499 (100%)]\tLoss: 0.835821\n",
      "\n",
      "Test set: Average loss: 0.9224, Accuracy: 271/500 (54%)\n",
      "\n",
      "Train Epoch: 78 [1499/1499 (100%)]\tLoss: 0.835583\n",
      "\n",
      "Test set: Average loss: 0.9171, Accuracy: 282/500 (56%)\n",
      "\n",
      "Train Epoch: 79 [1499/1499 (100%)]\tLoss: 0.834767\n",
      "\n",
      "Test set: Average loss: 0.9214, Accuracy: 272/500 (54%)\n",
      "\n",
      "Train Epoch: 80 [1499/1499 (100%)]\tLoss: 0.831375\n",
      "\n",
      "Test set: Average loss: 0.9134, Accuracy: 287/500 (57%)\n",
      "\n",
      "Train Epoch: 81 [1499/1499 (100%)]\tLoss: 0.825726\n",
      "\n",
      "Test set: Average loss: 0.9114, Accuracy: 285/500 (57%)\n",
      "\n",
      "Train Epoch: 82 [1499/1499 (100%)]\tLoss: 0.821347\n",
      "\n",
      "Test set: Average loss: 0.9132, Accuracy: 278/500 (56%)\n",
      "\n",
      "Train Epoch: 83 [1499/1499 (100%)]\tLoss: 0.818674\n",
      "\n",
      "Test set: Average loss: 0.9067, Accuracy: 290/500 (58%)\n",
      "\n",
      "Train Epoch: 84 [1499/1499 (100%)]\tLoss: 0.815810\n",
      "\n",
      "Test set: Average loss: 0.9090, Accuracy: 287/500 (57%)\n",
      "\n",
      "Train Epoch: 85 [1499/1499 (100%)]\tLoss: 0.812489\n",
      "\n",
      "Test set: Average loss: 0.9074, Accuracy: 288/500 (58%)\n",
      "\n",
      "Train Epoch: 86 [1499/1499 (100%)]\tLoss: 0.811079\n",
      "\n",
      "Test set: Average loss: 0.9095, Accuracy: 289/500 (58%)\n",
      "\n",
      "Train Epoch: 87 [1499/1499 (100%)]\tLoss: 0.812361\n",
      "\n",
      "Test set: Average loss: 0.9127, Accuracy: 289/500 (58%)\n",
      "\n",
      "Train Epoch: 88 [1499/1499 (100%)]\tLoss: 0.812607\n",
      "\n",
      "Test set: Average loss: 0.9164, Accuracy: 290/500 (58%)\n",
      "\n",
      "Train Epoch: 89 [1499/1499 (100%)]\tLoss: 0.813992\n",
      "\n",
      "Test set: Average loss: 0.9110, Accuracy: 288/500 (58%)\n",
      "\n",
      "Train Epoch: 90 [1499/1499 (100%)]\tLoss: 0.812609\n",
      "\n",
      "Test set: Average loss: 0.9191, Accuracy: 277/500 (55%)\n",
      "\n",
      "Train Epoch: 91 [1499/1499 (100%)]\tLoss: 0.810390\n",
      "\n",
      "Test set: Average loss: 0.9031, Accuracy: 295/500 (59%)\n",
      "\n",
      "Train Epoch: 92 [1499/1499 (100%)]\tLoss: 0.801705\n",
      "\n",
      "Test set: Average loss: 0.8998, Accuracy: 292/500 (58%)\n",
      "\n",
      "Train Epoch: 93 [1499/1499 (100%)]\tLoss: 0.792250\n",
      "\n",
      "Test set: Average loss: 0.9059, Accuracy: 282/500 (56%)\n",
      "\n",
      "Train Epoch: 94 [1499/1499 (100%)]\tLoss: 0.794248\n",
      "\n",
      "Test set: Average loss: 0.9027, Accuracy: 295/500 (59%)\n",
      "\n",
      "Train Epoch: 95 [1499/1499 (100%)]\tLoss: 0.798127\n",
      "\n",
      "Test set: Average loss: 0.9069, Accuracy: 290/500 (58%)\n",
      "\n",
      "Train Epoch: 96 [1499/1499 (100%)]\tLoss: 0.793234\n",
      "\n",
      "Test set: Average loss: 0.9027, Accuracy: 292/500 (58%)\n",
      "\n",
      "Train Epoch: 97 [1499/1499 (100%)]\tLoss: 0.788387\n",
      "\n",
      "Test set: Average loss: 0.8972, Accuracy: 297/500 (59%)\n",
      "\n",
      "Train Epoch: 98 [1499/1499 (100%)]\tLoss: 0.785829\n",
      "\n",
      "Test set: Average loss: 0.8998, Accuracy: 282/500 (56%)\n",
      "\n",
      "Train Epoch: 99 [1499/1499 (100%)]\tLoss: 0.781359\n",
      "\n",
      "Test set: Average loss: 0.8966, Accuracy: 298/500 (60%)\n",
      "\n",
      "Train Epoch: 100 [1499/1499 (100%)]\tLoss: 0.779727\n",
      "\n",
      "Test set: Average loss: 0.8995, Accuracy: 301/500 (60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100 + 1):\n",
    "    train(X_train,y_train,epoch)\n",
    "    test(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9482, Accuracy: 267/500 (53%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
