{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cifar10 - Aumento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetir o treinamento feito com os 2000 dados de treinamento feito na semana passada, porém agora com a técnica de aumento de dados mostrado na classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/etc/jupyterhub/ia368z_2s2017/datasets/cifar10-redux.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 3, 32, 32), (2000,), (500, 3, 32, 32), (500,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "y_train = keras.utils.to_categorical(y_train-3, num_classes)\n",
    "y_test_categorical = y_test-3\n",
    "y_test = keras.utils.to_categorical(y_test-3, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SmallCNN(nclasses,input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape,data_format=\"channels_first\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(nclasses))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Main cell\n",
    "model = SmallCNN(3,(3, 32, 32))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "opt = keras.optimizers.Adam()\n",
    "# initiate the Early Stop callback\n",
    "callbacks = []\n",
    "callbacks.append(EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Data normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "\n",
    "# Split the X_train to validation\n",
    "X_val = X_train[1500:]\n",
    "y_val = y_train[1500:]\n",
    "X_train = X_train[0:1499]\n",
    "y_train = y_train[0:1499]\n",
    "\n",
    "# The datagen will generate more sample from our previous dataset\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,data_format=\"channels_first\")  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "93/93 [==============================] - 30s - loss: 1.0729 - acc: 0.4048 - val_loss: 0.9608 - val_acc: 0.5260\n",
      "Epoch 2/25\n",
      "93/93 [==============================] - 27s - loss: 0.9520 - acc: 0.5331 - val_loss: 0.8909 - val_acc: 0.5580\n",
      "Epoch 3/25\n",
      "93/93 [==============================] - 27s - loss: 0.8835 - acc: 0.5626 - val_loss: 0.8612 - val_acc: 0.5940\n",
      "Epoch 4/25\n",
      "93/93 [==============================] - 27s - loss: 0.8551 - acc: 0.5958 - val_loss: 0.8234 - val_acc: 0.6140\n",
      "Epoch 5/25\n",
      "93/93 [==============================] - 27s - loss: 0.8602 - acc: 0.5998 - val_loss: 0.8299 - val_acc: 0.6060\n",
      "Epoch 6/25\n",
      "76/93 [=======================>......] - ETA: 4s - loss: 0.8313 - acc: 0.6110"
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, y_train,batch_size=30),\n",
    "                    steps_per_epoch=X_train.shape[0] // 16,\n",
    "                    epochs=25,\n",
    "                    validation_data=(X_val, y_val),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s     \n",
      "0.622000000954\n"
     ]
    }
   ],
   "source": [
    "# Run the model in X_test\n",
    "evaluation = model.evaluate(X_test,y_test)\n",
    "print(evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for the correct classifications and with less prediction probability\n",
    "prediction = model.predict(X_test)\n",
    "prediction_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_class_index = []\n",
    "prediction_correct = (np.argmax(prediction,axis=1)==y_test_categorical)\n",
    "for i in range(len(prediction_correct)):\n",
    "    if prediction_correct[i]:\n",
    "        prediction_class_index.append((prediction_proba[i].max(),i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype=np.dtype([('prob',float),('index',int)])\n",
    "less_prob_predictions = np.sort(np.array(prediction_class_index,dtype=dtype),order=\"prob\")[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    idx = less_prob_predictions[i][1]\n",
    "    prob = less_prob_predictions[i][0]\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(X_test[idx].transpose((1,2,0)))\n",
    "    plt.title('{}:{}:{:0.3f}'.format(y_test_categorical[idx],np.argmax(prediction,axis=1)[idx],prob))\n",
    "    plt.axis('off')\n",
    "plt.savefig('cifar_fig.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
